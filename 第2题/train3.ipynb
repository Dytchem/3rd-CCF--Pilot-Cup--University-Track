{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "590792a5-cddf-4a5d-aaef-da554f16ab4c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyqpanda as pq\n",
    "import pyvqnet as pv\n",
    "import random\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00d0bd95-484a-4e3d-b491-677e8a0ec9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Dataset(\n",
    "    \"data/cifar-10-batches-py/data_batch_1\",\n",
    "    \"data/cifar-10-batches-py/data_batch_2\",\n",
    "    \"data/cifar-10-batches-py/data_batch_3\",\n",
    "    \"data/cifar-10-batches-py/data_batch_4\",\n",
    "    \"data/cifar-10-batches-py/data_batch_5\",\n",
    ")\n",
    "test_data = Dataset(\"data/cifar-10-batches-py/test_batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87bb597e-1bd2-4614-96c0-d0d9096bdcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(pv.nn.module.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = pv.nn.Conv2D(3, 64, (3, 3), (1, 1))\n",
    "        self.pool1 = pv.nn.MaxPool2D((2, 2), (2, 2))\n",
    "        self.conv2 = pv.nn.Conv2D(64, 128, (4, 4), (1, 1))\n",
    "        self.pool2 = pv.nn.MaxPool2D((2, 2), (2, 2))\n",
    "        self.conv3 = pv.nn.Conv2D(128, 32, (5, 5), (1, 1))\n",
    "        self.pool3 = pv.nn.MaxPool2D((2, 2), (2, 2))\n",
    "        self.li = pv.nn.Linear(32 * 1 * 1, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.pool3(x)\n",
    "        x = pv.tensor.flatten(x, 1)\n",
    "        x = self.li(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a295ff97-6006-46b0-90e1-a09a8f953469",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 \t batch 10*100 \t loss 2.29 \t accuracy 0.10\n",
      "epoch 1 \t batch 10*200 \t loss 2.18 \t accuracy 0.10\n",
      "epoch 1 \t batch 10*300 \t loss 1.89 \t accuracy 0.20\n",
      "epoch 1 \t batch 10*400 \t loss 1.89 \t accuracy 0.40\n",
      "epoch 1 \t batch 10*500 \t loss 1.88 \t accuracy 0.30\n",
      "epoch 1 \t batch 10*600 \t loss 2.12 \t accuracy 0.20\n",
      "epoch 1 \t batch 10*700 \t loss 1.81 \t accuracy 0.40\n",
      "epoch 1 \t batch 10*800 \t loss 1.54 \t accuracy 0.60\n",
      "epoch 1 \t batch 10*900 \t loss 1.71 \t accuracy 0.30\n",
      "epoch 1 \t batch 10*1000 \t loss 1.58 \t accuracy 0.40\n",
      "epoch 1 \t batch 10*1100 \t loss 1.32 \t accuracy 0.70\n",
      "epoch 1 \t batch 10*1200 \t loss 2.00 \t accuracy 0.30\n",
      "epoch 1 \t batch 10*1300 \t loss 1.47 \t accuracy 0.30\n",
      "epoch 1 \t batch 10*1400 \t loss 1.82 \t accuracy 0.30\n",
      "epoch 1 \t batch 10*1500 \t loss 1.68 \t accuracy 0.30\n",
      "epoch 1 \t batch 10*1600 \t loss 2.90 \t accuracy 0.30\n",
      "epoch 1 \t batch 10*1700 \t loss 1.09 \t accuracy 0.80\n",
      "epoch 1 \t batch 10*1800 \t loss 1.43 \t accuracy 0.60\n",
      "epoch 1 \t batch 10*1900 \t loss 1.90 \t accuracy 0.40\n",
      "epoch 1 \t batch 10*2000 \t loss 1.83 \t accuracy 0.40\n",
      "epoch 1 \t batch 10*2100 \t loss 1.42 \t accuracy 0.30\n",
      "epoch 1 \t batch 10*2200 \t loss 1.37 \t accuracy 0.60\n",
      "epoch 1 \t batch 10*2300 \t loss 1.47 \t accuracy 0.50\n",
      "epoch 1 \t batch 10*2400 \t loss 1.29 \t accuracy 0.60\n",
      "epoch 1 \t batch 10*2500 \t loss 1.26 \t accuracy 0.50\n",
      "epoch 1 \t batch 10*2600 \t loss 1.38 \t accuracy 0.50\n",
      "epoch 1 \t batch 10*2700 \t loss 1.41 \t accuracy 0.60\n",
      "epoch 1 \t batch 10*2800 \t loss 1.94 \t accuracy 0.50\n",
      "epoch 1 \t batch 10*2900 \t loss 1.37 \t accuracy 0.40\n",
      "epoch 1 \t batch 10*3000 \t loss 1.49 \t accuracy 0.40\n",
      "epoch 1 \t batch 10*3100 \t loss 1.50 \t accuracy 0.60\n",
      "epoch 1 \t batch 10*3200 \t loss 1.20 \t accuracy 0.60\n",
      "epoch 1 \t batch 10*3300 \t loss 1.32 \t accuracy 0.60\n",
      "epoch 1 \t batch 10*3400 \t loss 2.09 \t accuracy 0.20\n",
      "epoch 1 \t batch 10*3500 \t loss 1.28 \t accuracy 0.60\n",
      "epoch 1 \t batch 10*3600 \t loss 1.91 \t accuracy 0.30\n",
      "epoch 1 \t batch 10*3700 \t loss 1.42 \t accuracy 0.60\n",
      "epoch 1 \t batch 10*3800 \t loss 1.22 \t accuracy 0.50\n",
      "epoch 1 \t batch 10*3900 \t loss 1.38 \t accuracy 0.60\n",
      "epoch 1 \t batch 10*4000 \t loss 2.17 \t accuracy 0.20\n",
      "********** train: epoch 1 \t accuracy 40.02% **********\n",
      "********** test: epoch 1 \t accuracy 47.07% **********\n",
      "epoch 2 \t batch 10*100 \t loss 1.50 \t accuracy 0.60\n",
      "epoch 2 \t batch 10*200 \t loss 1.07 \t accuracy 0.70\n",
      "epoch 2 \t batch 10*300 \t loss 2.11 \t accuracy 0.40\n",
      "epoch 2 \t batch 10*400 \t loss 1.25 \t accuracy 0.60\n",
      "epoch 2 \t batch 10*500 \t loss 1.87 \t accuracy 0.60\n",
      "epoch 2 \t batch 10*600 \t loss 1.80 \t accuracy 0.40\n",
      "epoch 2 \t batch 10*700 \t loss 1.83 \t accuracy 0.30\n",
      "epoch 2 \t batch 10*800 \t loss 1.48 \t accuracy 0.50\n",
      "epoch 2 \t batch 10*900 \t loss 1.02 \t accuracy 0.50\n",
      "epoch 2 \t batch 10*1000 \t loss 1.13 \t accuracy 0.60\n",
      "epoch 2 \t batch 10*1100 \t loss 1.74 \t accuracy 0.50\n",
      "epoch 2 \t batch 10*1200 \t loss 1.46 \t accuracy 0.70\n",
      "epoch 2 \t batch 10*1300 \t loss 2.17 \t accuracy 0.20\n",
      "epoch 2 \t batch 10*1400 \t loss 1.42 \t accuracy 0.40\n",
      "epoch 2 \t batch 10*1500 \t loss 1.74 \t accuracy 0.40\n",
      "epoch 2 \t batch 10*1600 \t loss 1.34 \t accuracy 0.60\n",
      "epoch 2 \t batch 10*1700 \t loss 1.30 \t accuracy 0.50\n",
      "epoch 2 \t batch 10*1800 \t loss 1.26 \t accuracy 0.70\n",
      "epoch 2 \t batch 10*1900 \t loss 1.38 \t accuracy 0.40\n",
      "epoch 2 \t batch 10*2000 \t loss 1.70 \t accuracy 0.40\n",
      "epoch 2 \t batch 10*2100 \t loss 1.98 \t accuracy 0.40\n",
      "epoch 2 \t batch 10*2200 \t loss 0.83 \t accuracy 0.70\n",
      "epoch 2 \t batch 10*2300 \t loss 1.15 \t accuracy 0.50\n",
      "epoch 2 \t batch 10*2400 \t loss 1.68 \t accuracy 0.30\n",
      "epoch 2 \t batch 10*2500 \t loss 1.42 \t accuracy 0.40\n",
      "epoch 2 \t batch 10*2600 \t loss 1.64 \t accuracy 0.30\n",
      "epoch 2 \t batch 10*2700 \t loss 2.16 \t accuracy 0.40\n",
      "epoch 2 \t batch 10*2800 \t loss 0.86 \t accuracy 0.60\n",
      "epoch 2 \t batch 10*2900 \t loss 0.93 \t accuracy 0.60\n",
      "epoch 2 \t batch 10*3000 \t loss 0.96 \t accuracy 0.70\n",
      "epoch 2 \t batch 10*3100 \t loss 1.04 \t accuracy 0.70\n",
      "epoch 2 \t batch 10*3200 \t loss 1.21 \t accuracy 0.50\n",
      "epoch 2 \t batch 10*3300 \t loss 1.21 \t accuracy 0.60\n",
      "epoch 2 \t batch 10*3400 \t loss 1.75 \t accuracy 0.30\n",
      "epoch 2 \t batch 10*3500 \t loss 1.00 \t accuracy 0.60\n",
      "epoch 2 \t batch 10*3600 \t loss 1.82 \t accuracy 0.40\n",
      "epoch 2 \t batch 10*3700 \t loss 0.92 \t accuracy 0.70\n",
      "epoch 2 \t batch 10*3800 \t loss 1.58 \t accuracy 0.60\n",
      "epoch 2 \t batch 10*3900 \t loss 0.92 \t accuracy 0.70\n",
      "epoch 2 \t batch 10*4000 \t loss 1.59 \t accuracy 0.30\n",
      "********** train: epoch 2 \t accuracy 54.13% **********\n",
      "********** test: epoch 2 \t accuracy 56.71% **********\n",
      "epoch 3 \t batch 10*100 \t loss 1.42 \t accuracy 0.60\n",
      "epoch 3 \t batch 10*200 \t loss 0.95 \t accuracy 0.60\n",
      "epoch 3 \t batch 10*300 \t loss 1.32 \t accuracy 0.70\n",
      "epoch 3 \t batch 10*400 \t loss 1.26 \t accuracy 0.60\n",
      "epoch 3 \t batch 10*500 \t loss 1.12 \t accuracy 0.60\n",
      "epoch 3 \t batch 10*600 \t loss 0.83 \t accuracy 0.80\n",
      "epoch 3 \t batch 10*700 \t loss 1.55 \t accuracy 0.60\n",
      "epoch 3 \t batch 10*800 \t loss 1.52 \t accuracy 0.50\n",
      "epoch 3 \t batch 10*900 \t loss 1.43 \t accuracy 0.50\n",
      "epoch 3 \t batch 10*1000 \t loss 1.33 \t accuracy 0.30\n",
      "epoch 3 \t batch 10*1100 \t loss 0.95 \t accuracy 0.70\n",
      "epoch 3 \t batch 10*1200 \t loss 1.02 \t accuracy 0.60\n",
      "epoch 3 \t batch 10*1300 \t loss 0.95 \t accuracy 0.70\n",
      "epoch 3 \t batch 10*1400 \t loss 1.02 \t accuracy 0.50\n",
      "epoch 3 \t batch 10*1500 \t loss 1.93 \t accuracy 0.30\n",
      "epoch 3 \t batch 10*1600 \t loss 1.39 \t accuracy 0.30\n",
      "epoch 3 \t batch 10*1700 \t loss 0.66 \t accuracy 0.70\n",
      "epoch 3 \t batch 10*1800 \t loss 1.43 \t accuracy 0.50\n",
      "epoch 3 \t batch 10*1900 \t loss 1.54 \t accuracy 0.50\n",
      "epoch 3 \t batch 10*2000 \t loss 1.24 \t accuracy 0.60\n",
      "epoch 3 \t batch 10*2100 \t loss 0.97 \t accuracy 0.70\n",
      "epoch 3 \t batch 10*2200 \t loss 1.70 \t accuracy 0.50\n",
      "epoch 3 \t batch 10*2300 \t loss 1.60 \t accuracy 0.40\n",
      "epoch 3 \t batch 10*2400 \t loss 1.07 \t accuracy 0.70\n",
      "epoch 3 \t batch 10*2500 \t loss 1.42 \t accuracy 0.30\n",
      "epoch 3 \t batch 10*2600 \t loss 0.91 \t accuracy 0.50\n",
      "epoch 3 \t batch 10*2700 \t loss 1.37 \t accuracy 0.30\n",
      "epoch 3 \t batch 10*2800 \t loss 0.72 \t accuracy 0.90\n",
      "epoch 3 \t batch 10*2900 \t loss 1.02 \t accuracy 0.70\n",
      "epoch 3 \t batch 10*3000 \t loss 0.68 \t accuracy 0.90\n",
      "epoch 3 \t batch 10*3100 \t loss 1.21 \t accuracy 0.70\n",
      "epoch 3 \t batch 10*3200 \t loss 1.59 \t accuracy 0.50\n",
      "epoch 3 \t batch 10*3300 \t loss 0.74 \t accuracy 0.80\n",
      "epoch 3 \t batch 10*3400 \t loss 2.35 \t accuracy 0.30\n",
      "epoch 3 \t batch 10*3500 \t loss 1.69 \t accuracy 0.40\n",
      "epoch 3 \t batch 10*3600 \t loss 1.37 \t accuracy 0.60\n",
      "epoch 3 \t batch 10*3700 \t loss 1.16 \t accuracy 0.70\n",
      "epoch 3 \t batch 10*3800 \t loss 1.60 \t accuracy 0.40\n",
      "epoch 3 \t batch 10*3900 \t loss 1.09 \t accuracy 0.60\n",
      "epoch 3 \t batch 10*4000 \t loss 1.27 \t accuracy 0.50\n",
      "********** train: epoch 3 \t accuracy 60.16% **********\n",
      "********** test: epoch 3 \t accuracy 61.11% **********\n",
      "epoch 4 \t batch 10*100 \t loss 1.05 \t accuracy 0.70\n",
      "epoch 4 \t batch 10*200 \t loss 1.04 \t accuracy 0.60\n",
      "epoch 4 \t batch 10*300 \t loss 0.47 \t accuracy 0.90\n",
      "epoch 4 \t batch 10*400 \t loss 1.18 \t accuracy 0.70\n",
      "epoch 4 \t batch 10*500 \t loss 0.93 \t accuracy 0.60\n",
      "epoch 4 \t batch 10*600 \t loss 1.26 \t accuracy 0.50\n",
      "epoch 4 \t batch 10*700 \t loss 0.80 \t accuracy 0.70\n",
      "epoch 4 \t batch 10*800 \t loss 0.95 \t accuracy 0.70\n",
      "epoch 4 \t batch 10*900 \t loss 1.25 \t accuracy 0.60\n",
      "epoch 4 \t batch 10*1000 \t loss 1.01 \t accuracy 0.70\n",
      "epoch 4 \t batch 10*1100 \t loss 1.03 \t accuracy 0.60\n",
      "epoch 4 \t batch 10*1200 \t loss 0.37 \t accuracy 0.90\n",
      "epoch 4 \t batch 10*1300 \t loss 1.49 \t accuracy 0.30\n",
      "epoch 4 \t batch 10*1400 \t loss 1.28 \t accuracy 0.60\n",
      "epoch 4 \t batch 10*1500 \t loss 0.69 \t accuracy 0.80\n",
      "epoch 4 \t batch 10*1600 \t loss 0.93 \t accuracy 0.60\n",
      "epoch 4 \t batch 10*1700 \t loss 0.86 \t accuracy 0.60\n",
      "epoch 4 \t batch 10*1800 \t loss 0.43 \t accuracy 1.00\n",
      "epoch 4 \t batch 10*1900 \t loss 1.17 \t accuracy 0.60\n",
      "epoch 4 \t batch 10*2000 \t loss 0.84 \t accuracy 0.70\n",
      "epoch 4 \t batch 10*2100 \t loss 1.23 \t accuracy 0.50\n",
      "epoch 4 \t batch 10*2200 \t loss 0.61 \t accuracy 0.80\n",
      "epoch 4 \t batch 10*2300 \t loss 0.76 \t accuracy 0.70\n",
      "epoch 4 \t batch 10*2400 \t loss 0.94 \t accuracy 0.60\n",
      "epoch 4 \t batch 10*2500 \t loss 1.08 \t accuracy 0.80\n",
      "epoch 4 \t batch 10*2600 \t loss 0.59 \t accuracy 0.90\n",
      "epoch 4 \t batch 10*2700 \t loss 1.31 \t accuracy 0.50\n",
      "epoch 4 \t batch 10*2800 \t loss 1.46 \t accuracy 0.60\n",
      "epoch 4 \t batch 10*2900 \t loss 1.31 \t accuracy 0.60\n",
      "epoch 4 \t batch 10*3000 \t loss 1.19 \t accuracy 0.70\n",
      "epoch 4 \t batch 10*3100 \t loss 0.96 \t accuracy 0.80\n",
      "epoch 4 \t batch 10*3200 \t loss 0.72 \t accuracy 0.80\n",
      "epoch 4 \t batch 10*3300 \t loss 1.01 \t accuracy 0.50\n",
      "epoch 4 \t batch 10*3400 \t loss 0.74 \t accuracy 0.70\n",
      "epoch 4 \t batch 10*3500 \t loss 1.05 \t accuracy 0.60\n",
      "epoch 4 \t batch 10*3600 \t loss 1.22 \t accuracy 0.50\n",
      "epoch 4 \t batch 10*3700 \t loss 0.62 \t accuracy 0.80\n",
      "epoch 4 \t batch 10*3800 \t loss 1.46 \t accuracy 0.60\n",
      "epoch 4 \t batch 10*3900 \t loss 1.01 \t accuracy 0.70\n",
      "epoch 4 \t batch 10*4000 \t loss 1.21 \t accuracy 0.60\n",
      "********** train: epoch 4 \t accuracy 64.00% **********\n",
      "********** test: epoch 4 \t accuracy 61.94% **********\n",
      "epoch 5 \t batch 10*100 \t loss 0.70 \t accuracy 0.70\n",
      "epoch 5 \t batch 10*200 \t loss 1.11 \t accuracy 0.60\n",
      "epoch 5 \t batch 10*300 \t loss 0.84 \t accuracy 0.70\n",
      "epoch 5 \t batch 10*400 \t loss 1.03 \t accuracy 0.70\n",
      "epoch 5 \t batch 10*500 \t loss 1.20 \t accuracy 0.50\n",
      "epoch 5 \t batch 10*600 \t loss 0.96 \t accuracy 0.60\n",
      "epoch 5 \t batch 10*700 \t loss 1.12 \t accuracy 0.60\n",
      "epoch 5 \t batch 10*800 \t loss 0.66 \t accuracy 0.80\n",
      "epoch 5 \t batch 10*900 \t loss 0.64 \t accuracy 0.80\n",
      "epoch 5 \t batch 10*1000 \t loss 0.86 \t accuracy 0.50\n",
      "epoch 5 \t batch 10*1100 \t loss 0.78 \t accuracy 0.80\n",
      "epoch 5 \t batch 10*1200 \t loss 0.61 \t accuracy 0.70\n",
      "epoch 5 \t batch 10*1300 \t loss 0.45 \t accuracy 0.70\n",
      "epoch 5 \t batch 10*1400 \t loss 1.37 \t accuracy 0.50\n",
      "epoch 5 \t batch 10*1500 \t loss 0.96 \t accuracy 0.80\n",
      "epoch 5 \t batch 10*1600 \t loss 0.94 \t accuracy 0.80\n",
      "epoch 5 \t batch 10*1700 \t loss 0.73 \t accuracy 0.60\n",
      "epoch 5 \t batch 10*1800 \t loss 1.54 \t accuracy 0.70\n",
      "epoch 5 \t batch 10*1900 \t loss 0.60 \t accuracy 0.80\n",
      "epoch 5 \t batch 10*2000 \t loss 0.97 \t accuracy 0.50\n",
      "epoch 5 \t batch 10*2100 \t loss 0.93 \t accuracy 0.50\n",
      "epoch 5 \t batch 10*2200 \t loss 0.73 \t accuracy 0.60\n",
      "epoch 5 \t batch 10*2300 \t loss 1.05 \t accuracy 0.60\n",
      "epoch 5 \t batch 10*2400 \t loss 0.35 \t accuracy 0.90\n",
      "epoch 5 \t batch 10*2500 \t loss 0.67 \t accuracy 0.80\n",
      "epoch 5 \t batch 10*2600 \t loss 0.41 \t accuracy 1.00\n",
      "epoch 5 \t batch 10*2700 \t loss 0.83 \t accuracy 0.60\n",
      "epoch 5 \t batch 10*2800 \t loss 1.18 \t accuracy 0.70\n",
      "epoch 5 \t batch 10*2900 \t loss 0.77 \t accuracy 0.60\n",
      "epoch 5 \t batch 10*3000 \t loss 0.95 \t accuracy 0.80\n",
      "epoch 5 \t batch 10*3100 \t loss 0.71 \t accuracy 0.70\n",
      "epoch 5 \t batch 10*3200 \t loss 1.34 \t accuracy 0.40\n",
      "epoch 5 \t batch 10*3300 \t loss 1.27 \t accuracy 0.40\n",
      "epoch 5 \t batch 10*3400 \t loss 0.43 \t accuracy 0.90\n",
      "epoch 5 \t batch 10*3500 \t loss 2.29 \t accuracy 0.30\n",
      "epoch 5 \t batch 10*3600 \t loss 0.96 \t accuracy 0.60\n",
      "epoch 5 \t batch 10*3700 \t loss 0.93 \t accuracy 0.70\n",
      "epoch 5 \t batch 10*3800 \t loss 0.90 \t accuracy 0.70\n",
      "epoch 5 \t batch 10*3900 \t loss 0.83 \t accuracy 0.70\n",
      "epoch 5 \t batch 10*4000 \t loss 0.68 \t accuracy 0.70\n",
      "********** train: epoch 5 \t accuracy 66.52% **********\n",
      "********** test: epoch 5 \t accuracy 63.83% **********\n",
      "epoch 6 \t batch 10*100 \t loss 0.51 \t accuracy 0.80\n",
      "epoch 6 \t batch 10*200 \t loss 0.67 \t accuracy 0.80\n",
      "epoch 6 \t batch 10*300 \t loss 0.57 \t accuracy 0.80\n",
      "epoch 6 \t batch 10*400 \t loss 0.76 \t accuracy 0.80\n",
      "epoch 6 \t batch 10*500 \t loss 1.00 \t accuracy 0.60\n",
      "epoch 6 \t batch 10*600 \t loss 0.55 \t accuracy 0.70\n",
      "epoch 6 \t batch 10*700 \t loss 1.36 \t accuracy 0.40\n",
      "epoch 6 \t batch 10*800 \t loss 1.77 \t accuracy 0.30\n",
      "epoch 6 \t batch 10*900 \t loss 1.38 \t accuracy 0.80\n",
      "epoch 6 \t batch 10*1000 \t loss 0.61 \t accuracy 0.80\n",
      "epoch 6 \t batch 10*1100 \t loss 0.52 \t accuracy 0.80\n",
      "epoch 6 \t batch 10*1200 \t loss 0.88 \t accuracy 0.80\n",
      "epoch 6 \t batch 10*1300 \t loss 0.92 \t accuracy 0.50\n",
      "epoch 6 \t batch 10*1400 \t loss 0.50 \t accuracy 0.70\n",
      "epoch 6 \t batch 10*1500 \t loss 0.73 \t accuracy 0.80\n",
      "epoch 6 \t batch 10*1600 \t loss 1.57 \t accuracy 0.60\n",
      "epoch 6 \t batch 10*1700 \t loss 0.79 \t accuracy 0.80\n",
      "epoch 6 \t batch 10*1800 \t loss 1.70 \t accuracy 0.50\n",
      "epoch 6 \t batch 10*1900 \t loss 0.79 \t accuracy 0.60\n",
      "epoch 6 \t batch 10*2000 \t loss 0.47 \t accuracy 0.90\n",
      "epoch 6 \t batch 10*2100 \t loss 0.60 \t accuracy 0.80\n",
      "epoch 6 \t batch 10*2200 \t loss 0.24 \t accuracy 1.00\n",
      "epoch 6 \t batch 10*2300 \t loss 0.66 \t accuracy 0.70\n",
      "epoch 6 \t batch 10*2400 \t loss 1.85 \t accuracy 0.60\n",
      "epoch 6 \t batch 10*2500 \t loss 0.79 \t accuracy 0.70\n",
      "epoch 6 \t batch 10*2600 \t loss 0.59 \t accuracy 0.80\n",
      "epoch 6 \t batch 10*2700 \t loss 0.99 \t accuracy 0.80\n",
      "epoch 6 \t batch 10*2800 \t loss 0.78 \t accuracy 0.70\n",
      "epoch 6 \t batch 10*2900 \t loss 0.89 \t accuracy 0.70\n",
      "epoch 6 \t batch 10*3000 \t loss 1.78 \t accuracy 0.40\n",
      "epoch 6 \t batch 10*3100 \t loss 0.74 \t accuracy 0.60\n",
      "epoch 6 \t batch 10*3200 \t loss 1.52 \t accuracy 0.60\n",
      "epoch 6 \t batch 10*3300 \t loss 0.92 \t accuracy 0.60\n",
      "epoch 6 \t batch 10*3400 \t loss 1.07 \t accuracy 0.70\n",
      "epoch 6 \t batch 10*3500 \t loss 1.05 \t accuracy 0.50\n",
      "epoch 6 \t batch 10*3600 \t loss 1.23 \t accuracy 0.50\n",
      "epoch 6 \t batch 10*3700 \t loss 0.94 \t accuracy 0.80\n",
      "epoch 6 \t batch 10*3800 \t loss 0.81 \t accuracy 0.70\n",
      "epoch 6 \t batch 10*3900 \t loss 0.76 \t accuracy 0.80\n",
      "epoch 6 \t batch 10*4000 \t loss 0.89 \t accuracy 0.80\n",
      "********** train: epoch 6 \t accuracy 68.79% **********\n",
      "********** test: epoch 6 \t accuracy 65.30% **********\n",
      "epoch 7 \t batch 10*100 \t loss 1.59 \t accuracy 0.50\n",
      "epoch 7 \t batch 10*200 \t loss 0.80 \t accuracy 0.70\n",
      "epoch 7 \t batch 10*300 \t loss 1.29 \t accuracy 0.40\n",
      "epoch 7 \t batch 10*400 \t loss 0.85 \t accuracy 0.70\n",
      "epoch 7 \t batch 10*500 \t loss 0.59 \t accuracy 0.70\n",
      "epoch 7 \t batch 10*600 \t loss 1.03 \t accuracy 0.60\n",
      "epoch 7 \t batch 10*700 \t loss 1.29 \t accuracy 0.50\n",
      "epoch 7 \t batch 10*800 \t loss 1.75 \t accuracy 0.50\n",
      "epoch 7 \t batch 10*900 \t loss 0.31 \t accuracy 0.90\n",
      "epoch 7 \t batch 10*1000 \t loss 0.86 \t accuracy 0.70\n",
      "epoch 7 \t batch 10*1100 \t loss 0.67 \t accuracy 0.80\n",
      "epoch 7 \t batch 10*1200 \t loss 0.48 \t accuracy 0.80\n",
      "epoch 7 \t batch 10*1300 \t loss 0.46 \t accuracy 0.70\n",
      "epoch 7 \t batch 10*1400 \t loss 0.92 \t accuracy 0.70\n",
      "epoch 7 \t batch 10*1500 \t loss 0.50 \t accuracy 0.80\n",
      "epoch 7 \t batch 10*1600 \t loss 0.77 \t accuracy 0.70\n",
      "epoch 7 \t batch 10*1700 \t loss 1.87 \t accuracy 0.50\n",
      "epoch 7 \t batch 10*1800 \t loss 1.30 \t accuracy 0.50\n",
      "epoch 7 \t batch 10*1900 \t loss 0.89 \t accuracy 0.80\n",
      "epoch 7 \t batch 10*2000 \t loss 0.57 \t accuracy 0.80\n",
      "epoch 7 \t batch 10*2100 \t loss 0.76 \t accuracy 0.80\n",
      "epoch 7 \t batch 10*2200 \t loss 1.15 \t accuracy 0.60\n",
      "epoch 7 \t batch 10*2300 \t loss 1.25 \t accuracy 0.60\n",
      "epoch 7 \t batch 10*2400 \t loss 0.95 \t accuracy 0.60\n",
      "epoch 7 \t batch 10*2500 \t loss 0.89 \t accuracy 0.60\n",
      "epoch 7 \t batch 10*2600 \t loss 0.92 \t accuracy 0.70\n",
      "epoch 7 \t batch 10*2700 \t loss 0.90 \t accuracy 0.70\n",
      "epoch 7 \t batch 10*2800 \t loss 1.47 \t accuracy 0.50\n",
      "epoch 7 \t batch 10*2900 \t loss 0.81 \t accuracy 0.80\n",
      "epoch 7 \t batch 10*3000 \t loss 0.91 \t accuracy 0.70\n",
      "epoch 7 \t batch 10*3100 \t loss 0.69 \t accuracy 0.80\n",
      "epoch 7 \t batch 10*3200 \t loss 0.64 \t accuracy 0.80\n",
      "epoch 7 \t batch 10*3300 \t loss 0.71 \t accuracy 0.70\n",
      "epoch 7 \t batch 10*3400 \t loss 1.00 \t accuracy 0.60\n",
      "epoch 7 \t batch 10*3500 \t loss 0.95 \t accuracy 0.60\n",
      "epoch 7 \t batch 10*3600 \t loss 0.53 \t accuracy 0.80\n",
      "epoch 7 \t batch 10*3700 \t loss 0.80 \t accuracy 0.70\n",
      "epoch 7 \t batch 10*3800 \t loss 0.72 \t accuracy 0.80\n",
      "epoch 7 \t batch 10*3900 \t loss 0.60 \t accuracy 0.80\n",
      "epoch 7 \t batch 10*4000 \t loss 1.18 \t accuracy 0.60\n",
      "********** train: epoch 7 \t accuracy 70.54% **********\n",
      "********** test: epoch 7 \t accuracy 64.60% **********\n",
      "epoch 8 \t batch 10*100 \t loss 0.83 \t accuracy 0.70\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m correct_tot \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m correct\n\u001b[0;32m     27\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 28\u001b[0m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m     31\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m*\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m accuracy \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     32\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch = 10\n",
    "batch = 10\n",
    "holdout = 10000\n",
    "\n",
    "model = Model()\n",
    "\n",
    "X, Y = train_data.getdatas()\n",
    "los = pv.nn.loss.CrossEntropyLoss()\n",
    "opt = pv.optim.SGD(model.parameters(), 0.01)\n",
    "\n",
    "for e in range(1, epoch + 1):\n",
    "    model.train()\n",
    "\n",
    "    correct_tot = 0\n",
    "    for I, (x, y) in enumerate(\n",
    "        pv.data.data_generator(\n",
    "            X[:-holdout], Y[:-holdout], batch_size=batch, shuffle=True\n",
    "        )\n",
    "    ):\n",
    "        i = I + 1\n",
    "        opt.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = los(y, y_pred)\n",
    "        correct = sum(y_pred.argmax(1, False).to_numpy() == y)\n",
    "        acc = correct / y.shape[0]\n",
    "        correct_tot += correct\n",
    "        loss.backward()\n",
    "        opt._step()\n",
    "        if i % 100 == 0:\n",
    "            print(\n",
    "                f\"epoch {e} \\t batch {batch}*{i} \\t loss {loss.item():.2f} \\t accuracy {acc:.2f}\"\n",
    "            )\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    acc = correct_tot / (Y.shape[0] - holdout)\n",
    "    print(f\"********** train: epoch {e} \\t accuracy {100*acc:.2f}% **********\")\n",
    "\n",
    "    correct_tot = 0\n",
    "    for x, y in pv.data.data_generator(\n",
    "        X[-holdout:], Y[-holdout:], batch_size=batch, shuffle=False\n",
    "    ):\n",
    "        y_pred = model(x)\n",
    "        correct_tot += sum(y_pred.argmax(1, False).to_numpy() == y)\n",
    "\n",
    "    acc = correct_tot / holdout\n",
    "    print(f\"********** test: epoch {e} \\t accuracy {100*acc:.2f}% **********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "402d77b3-2cad-4bce-aad4-e9acd9205e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pv.utils.storage.save_parameters(model.state_dict(), \"train3.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dca29aa3-7efa-4e0e-a97c-eb145820efd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Model()\n",
    "m.load_state_dict(pv.utils.storage.load_parameters(\"train3.model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7d444c3-c167-4ff0-b6dd-725bb01148a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** eval: accuracy 65.16% **********\n"
     ]
    }
   ],
   "source": [
    "m.eval()\n",
    "X, Y = test_data.getdatas()\n",
    "correct_tot = 0\n",
    "for x, y in pv.data.data_generator(X, Y, batch_size=batch, shuffle=False):\n",
    "    y_pred = model(x)\n",
    "    correct_tot += sum(y_pred.argmax(1, False).to_numpy() == y)\n",
    "acc = correct_tot / Y.shape[0]\n",
    "print(f\"********** eval: accuracy {100*acc:.2f}% **********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c91b698-5df4-46b1-9aa5-8950328b2068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c82a43a-b593-4feb-baf4-0174d6bf7ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fe0458-44ee-4fde-8fdc-79d528782f55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534048c2-cee7-49f3-ad6a-09a1b0150614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5640dd-406d-4843-9e05-0f9823b6461b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
