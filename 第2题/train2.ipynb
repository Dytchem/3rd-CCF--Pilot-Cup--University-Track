{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "926b16ea-ea93-40c0-ba9d-628afc80c609",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyqpanda as pq\n",
    "import pyvqnet as pv\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3947ad2-7aca-43b0-8643-4191c2651828",
   "metadata": {},
   "outputs": [],
   "source": [
    "pic_size = 32\n",
    "output_num = 10\n",
    "input_channels = 3\n",
    "output_channels = 1\n",
    "quantum_number = 4\n",
    "stride = (4, 4)\n",
    "pic_w = 32\n",
    "pic_h = 32\n",
    "output_num = 10\n",
    "\n",
    "epoch = 3\n",
    "batch = 100\n",
    "\n",
    "\n",
    "class Model(pv.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.vq = pv.qnn.qcnn.QConv(\n",
    "            input_channels, output_channels, quantum_number, stride\n",
    "        )\n",
    "        self.li = pv.nn.Linear(\n",
    "            output_channels * (pic_w // stride[0]) * (pic_h // stride[1]), output_num\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.vq(x)\n",
    "        x = pv.tensor.flatten(x, 1)\n",
    "        x = self.li(x)\n",
    "        x = pv.tensor.log_softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67d7d9b1-eede-437e-b383-35a1897572d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "\n",
    "    with open(file, \"rb\") as fo:\n",
    "        dict = pickle.load(fo, encoding=\"bytes\")\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fb3609e-99ad-4536-bbbf-182cd95f6915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader(file):\n",
    "    data = unpickle(file)\n",
    "    X = data[b\"data\"]\n",
    "    Y = data[b\"labels\"]\n",
    "    N = X.shape[0]\n",
    "    L = [i for i in range(N)]\n",
    "    random.shuffle(L)\n",
    "    now = 0\n",
    "    pic_tot = pic_w * pic_h\n",
    "    while now < N:\n",
    "        n = min(N - now, batch)\n",
    "        x = np.zeros([n, input_channels, pic_w, pic_h])\n",
    "        y = np.zeros([n], dtype=\"int64\")\n",
    "        for i in range(n):\n",
    "            for c in range(input_channels):\n",
    "                x[i, c] = (\n",
    "                    X[L[now]][pic_tot * c : pic_tot * (c + 1)].reshape((pic_w, pic_h))\n",
    "                    / 255\n",
    "                )\n",
    "            y[i] = Y[L[now]]\n",
    "            now += 1\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "400a7472-7d19-46be-91eb-01fdaae4b57e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# y=1\n",
    "# for x,y in dataloader(\"data/cifar-10-batches-py/data_batch_1\"):\n",
    "#     print(x.shape,y.shape)\n",
    "#     print(x)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "958198f7-707a-4d7e-becf-e8a23de0128b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 \tbatch 0 \tloss 2.3808026 \tcorrect 8\n",
      "epoch 0 \tbatch 1 \tloss 2.3498964 \tcorrect 19\n",
      "epoch 0 \tbatch 2 \tloss 2.3346283 \tcorrect 29\n",
      "epoch 0 \tbatch 3 \tloss 2.340718 \tcorrect 39\n",
      "epoch 0 \tbatch 4 \tloss 2.3235254 \tcorrect 48\n",
      "epoch 0 \tbatch 5 \tloss 2.344951 \tcorrect 56\n",
      "epoch 0 \tbatch 6 \tloss 2.3369017 \tcorrect 64\n",
      "epoch 0 \tbatch 7 \tloss 2.3292806 \tcorrect 80\n",
      "epoch 0 \tbatch 8 \tloss 2.3096075 \tcorrect 94\n",
      "epoch 0 \tbatch 9 \tloss 2.3946567 \tcorrect 103\n",
      "epoch 0 \tbatch 10 \tloss 2.3420844 \tcorrect 114\n",
      "epoch 0 \tbatch 11 \tloss 2.427244 \tcorrect 119\n",
      "epoch 0 \tbatch 12 \tloss 2.3467836 \tcorrect 127\n",
      "epoch 0 \tbatch 13 \tloss 2.3510702 \tcorrect 136\n",
      "epoch 0 \tbatch 14 \tloss 2.3678482 \tcorrect 146\n",
      "epoch 0 \tbatch 15 \tloss 2.3038132 \tcorrect 157\n",
      "epoch 0 \tbatch 16 \tloss 2.4310868 \tcorrect 165\n",
      "epoch 0 \tbatch 17 \tloss 2.3716319 \tcorrect 174\n",
      "epoch 0 \tbatch 18 \tloss 2.34245 \tcorrect 185\n",
      "epoch 0 \tbatch 19 \tloss 2.4065182 \tcorrect 200\n",
      "epoch 0 \tbatch 20 \tloss 2.3085928 \tcorrect 211\n",
      "epoch 0 \tbatch 21 \tloss 2.32447 \tcorrect 223\n",
      "epoch 0 \tbatch 22 \tloss 2.4044106 \tcorrect 233\n",
      "epoch 0 \tbatch 23 \tloss 2.3261971 \tcorrect 247\n",
      "epoch 0 \tbatch 24 \tloss 2.3470614 \tcorrect 260\n",
      "epoch 0 \tbatch 25 \tloss 2.3206844 \tcorrect 269\n",
      "epoch 0 \tbatch 26 \tloss 2.4071968 \tcorrect 277\n",
      "epoch 0 \tbatch 27 \tloss 2.3592553 \tcorrect 289\n",
      "epoch 0 \tbatch 28 \tloss 2.3502054 \tcorrect 299\n",
      "epoch 0 \tbatch 29 \tloss 2.330888 \tcorrect 309\n",
      "epoch 0 \tbatch 30 \tloss 2.2651947 \tcorrect 327\n",
      "epoch 0 \tbatch 31 \tloss 2.3639388 \tcorrect 333\n",
      "epoch 0 \tbatch 32 \tloss 2.3523605 \tcorrect 340\n",
      "epoch 0 \tbatch 33 \tloss 2.361781 \tcorrect 353\n",
      "epoch 0 \tbatch 34 \tloss 2.3759613 \tcorrect 363\n",
      "epoch 0 \tbatch 35 \tloss 2.3987718 \tcorrect 371\n",
      "epoch 0 \tbatch 36 \tloss 2.3661475 \tcorrect 380\n",
      "epoch 0 \tbatch 37 \tloss 2.309117 \tcorrect 391\n",
      "epoch 0 \tbatch 38 \tloss 2.3834994 \tcorrect 396\n",
      "epoch 0 \tbatch 39 \tloss 2.4065685 \tcorrect 406\n",
      "epoch 0 \tbatch 40 \tloss 2.3969674 \tcorrect 418\n",
      "epoch 0 \tbatch 41 \tloss 2.5198529 \tcorrect 424\n",
      "epoch 0 \tbatch 42 \tloss 2.3972023 \tcorrect 432\n",
      "epoch 0 \tbatch 43 \tloss 2.3590395 \tcorrect 448\n",
      "epoch 0 \tbatch 44 \tloss 2.4309604 \tcorrect 455\n",
      "epoch 0 \tbatch 45 \tloss 2.3578172 \tcorrect 463\n",
      "epoch 0 \tbatch 46 \tloss 2.357417 \tcorrect 478\n",
      "epoch 0 \tbatch 47 \tloss 2.3328073 \tcorrect 486\n",
      "epoch 0 \tbatch 48 \tloss 2.4099445 \tcorrect 495\n",
      "epoch 0 \tbatch 49 \tloss 2.3455613 \tcorrect 508\n",
      "epoch 0 \tbatch 50 \tloss 2.3829873 \tcorrect 520\n",
      "epoch 0 \tbatch 51 \tloss 2.3996606 \tcorrect 532\n",
      "epoch 0 \tbatch 52 \tloss 2.3562887 \tcorrect 539\n",
      "epoch 0 \tbatch 53 \tloss 2.4063363 \tcorrect 547\n",
      "epoch 0 \tbatch 54 \tloss 2.4319832 \tcorrect 558\n",
      "epoch 0 \tbatch 55 \tloss 2.3321497 \tcorrect 568\n",
      "epoch 0 \tbatch 56 \tloss 2.3264227 \tcorrect 582\n",
      "epoch 0 \tbatch 57 \tloss 2.3853836 \tcorrect 594\n",
      "epoch 0 \tbatch 58 \tloss 2.4246593 \tcorrect 602\n",
      "epoch 0 \tbatch 59 \tloss 2.4463472 \tcorrect 607\n",
      "epoch 0 \tbatch 60 \tloss 2.3635564 \tcorrect 621\n",
      "epoch 0 \tbatch 61 \tloss 2.4094017 \tcorrect 629\n",
      "epoch 0 \tbatch 62 \tloss 2.398611 \tcorrect 644\n",
      "epoch 0 \tbatch 63 \tloss 2.394511 \tcorrect 655\n",
      "epoch 0 \tbatch 64 \tloss 2.4679391 \tcorrect 663\n",
      "epoch 0 \tbatch 65 \tloss 2.4438481 \tcorrect 669\n",
      "epoch 0 \tbatch 66 \tloss 2.3469253 \tcorrect 676\n",
      "epoch 0 \tbatch 67 \tloss 2.41192 \tcorrect 684\n",
      "epoch 0 \tbatch 68 \tloss 2.424841 \tcorrect 688\n",
      "epoch 0 \tbatch 69 \tloss 2.4459412 \tcorrect 703\n",
      "epoch 0 \tbatch 70 \tloss 2.3727872 \tcorrect 710\n",
      "epoch 0 \tbatch 71 \tloss 2.3684995 \tcorrect 723\n",
      "epoch 0 \tbatch 72 \tloss 2.35897 \tcorrect 736\n",
      "epoch 0 \tbatch 73 \tloss 2.347008 \tcorrect 743\n",
      "epoch 0 \tbatch 74 \tloss 2.4935408 \tcorrect 752\n",
      "epoch 0 \tbatch 75 \tloss 2.4286692 \tcorrect 757\n",
      "epoch 0 \tbatch 76 \tloss 2.4935517 \tcorrect 760\n",
      "epoch 0 \tbatch 77 \tloss 2.3553207 \tcorrect 766\n",
      "epoch 0 \tbatch 78 \tloss 2.345194 \tcorrect 779\n",
      "epoch 0 \tbatch 79 \tloss 2.398705 \tcorrect 791\n",
      "epoch 0 \tbatch 80 \tloss 2.5033762 \tcorrect 796\n",
      "epoch 0 \tbatch 81 \tloss 2.3190398 \tcorrect 809\n",
      "epoch 0 \tbatch 82 \tloss 2.447802 \tcorrect 814\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m output \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[0;32m     14\u001b[0m loss \u001b[38;5;241m=\u001b[39m cceloss(y, output)\n\u001b[1;32m---> 16\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39m_step()\n\u001b[0;32m     19\u001b[0m full_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mpyvqnet\\tensor\\tensor.py:236\u001b[0m, in \u001b[0;36mpyvqnet.tensor.tensor.QTensor.backward\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpyvqnet\\tensor\\tensor.py:9204\u001b[0m, in \u001b[0;36mpyvqnet.tensor.tensor.backprop\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpyvqnet\\tensor\\tensor.py:9162\u001b[0m, in \u001b[0;36mpyvqnet.tensor.tensor.backprop_impl\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpyvqnet\\qnn\\qcnn\\qconv.py:482\u001b[0m, in \u001b[0;36mpyvqnet.qnn.qcnn.qconv.QConv.forward.lambda2\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpyvqnet\\qnn\\qcnn\\qconv.py:626\u001b[0m, in \u001b[0;36mpyvqnet.qnn.qcnn.qconv._q_conv_grad\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\anaconda3\\envs\\cp310\\lib\\site-packages\\numpy\\core\\numeric.py:132\u001b[0m, in \u001b[0;36mzeros_like\u001b[1;34m(a, dtype, order, subok, shape)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m# needed instead of a 0 to get same result as zeros for string dtypes\u001b[39;00m\n\u001b[0;32m    131\u001b[0m z \u001b[38;5;241m=\u001b[39m zeros(\u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m--> 132\u001b[0m \u001b[43mmultiarray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopyto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43munsafe\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "model.train()\n",
    "optimizer = pv.optim.SGD(model.parameters())\n",
    "cceloss = pv.nn.loss.NLL_Loss()\n",
    "\n",
    "for e in range(epoch):\n",
    "    full_loss = 0\n",
    "    n_loss = 0\n",
    "    n_eval = 0\n",
    "    correct = 0\n",
    "    for i, (x, y) in enumerate(dataloader(\"data/cifar-10-batches-py/data_batch_1\")):\n",
    "        print(\"epoch\", e, \"\\tbatch\", i, end = \" \")\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = cceloss(y, output)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer._step()\n",
    "\n",
    "        full_loss += loss.item()\n",
    "        n_loss += batch\n",
    "\n",
    "        np_output = np.array(output.data, copy=False)\n",
    "        mask = np_output.argmax(1) == y\n",
    "        correct += sum(mask)\n",
    "\n",
    "        print(\"\\tloss\", loss, \"\\tcorrect\", correct)\n",
    "    print(f\"Train Accuracy: {correct/n_loss}%\")\n",
    "    print(f\"Epoch: {epoch}, Loss: {full_loss / n_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e14716-b749-4721-ba45-7bcc996a7ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pv.utils.storage.save_parameters(model.state_dict(), \"train2.model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
