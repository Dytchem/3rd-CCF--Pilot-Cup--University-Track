{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "926b16ea-ea93-40c0-ba9d-628afc80c609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyqpanda as pq\n",
    "import pyvqnet as pv\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3947ad2-7aca-43b0-8643-4191c2651828",
   "metadata": {},
   "outputs": [],
   "source": [
    "pic_size = 32\n",
    "output_num = 10\n",
    "input_channels = 3\n",
    "output_channels = 1\n",
    "quantum_number = 4\n",
    "stride = (4, 4)\n",
    "pic_w = 32\n",
    "pic_h = 32\n",
    "output_num = 10\n",
    "\n",
    "epoch = 3\n",
    "batch = 100\n",
    "\n",
    "\n",
    "class Model(pv.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.vq = pv.qnn.qcnn.QConv(\n",
    "            input_channels, output_channels, quantum_number, stride\n",
    "        )\n",
    "        self.li = pv.nn.Linear(\n",
    "            output_channels * (pic_w // stride[0]) * (pic_h // stride[1]), output_num\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.vq(x)\n",
    "        x = pv.tensor.flatten(x, 1)\n",
    "        x = self.li(x)\n",
    "        x = pv.tensor.log_softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67d7d9b1-eede-437e-b383-35a1897572d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "\n",
    "    with open(file, \"rb\") as fo:\n",
    "        dict = pickle.load(fo, encoding=\"bytes\")\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fb3609e-99ad-4536-bbbf-182cd95f6915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader(file):\n",
    "    data = unpickle(file)\n",
    "    X = data[b\"data\"]\n",
    "    Y = data[b\"labels\"]\n",
    "    N = X.shape[0]\n",
    "    L = [i for i in range(N)]\n",
    "    random.shuffle(L)\n",
    "    now = 0\n",
    "    pic_tot = pic_w * pic_h\n",
    "    while now < N:\n",
    "        n = min(N - now, batch)\n",
    "        x = np.zeros([n, input_channels, pic_w, pic_h])\n",
    "        y = np.zeros([n], dtype=\"int64\")\n",
    "        for i in range(n):\n",
    "            for c in range(input_channels):\n",
    "                x[i, c] = (\n",
    "                    X[L[now]][pic_tot * c : pic_tot * (c + 1)].reshape((pic_w, pic_h))\n",
    "                    / 255\n",
    "                )\n",
    "            y[i] = Y[L[now]]\n",
    "            now += 1\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "400a7472-7d19-46be-91eb-01fdaae4b57e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# y=1\n",
    "# for x,y in dataloader(\"data/cifar-10-batches-py/data_batch_1\"):\n",
    "#     print(x.shape,y.shape)\n",
    "#     print(x)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958198f7-707a-4d7e-becf-e8a23de0128b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 \tbatch 0 \tloss 2.3808026 \tcorrect 8\n",
      "epoch 0 \tbatch 1 \tloss 2.3498964 \tcorrect 19\n",
      "epoch 0 \tbatch 2 \tloss 2.3346283 \tcorrect 29\n",
      "epoch 0 \tbatch 3 \tloss 2.340718 \tcorrect 39\n",
      "epoch 0 \tbatch 4 \tloss 2.3235254 \tcorrect 48\n",
      "epoch 0 \tbatch 5 \tloss 2.344951 \tcorrect 56\n",
      "epoch 0 \tbatch 6 \tloss 2.3369017 \tcorrect 64\n",
      "epoch 0 \tbatch 7 \tloss 2.3292806 \tcorrect 80\n",
      "epoch 0 \tbatch 8 \tloss 2.3096075 \tcorrect 94\n",
      "epoch 0 \tbatch 9 \tloss 2.3946567 \tcorrect 103\n",
      "epoch 0 \tbatch 10 \tloss 2.3420844 \tcorrect 114\n",
      "epoch 0 \tbatch 11 \tloss 2.427244 \tcorrect 119\n",
      "epoch 0 \tbatch 12 \tloss 2.3467836 \tcorrect 127\n",
      "epoch 0 \tbatch 13 \tloss 2.3510702 \tcorrect 136\n",
      "epoch 0 \tbatch 14 \tloss 2.3678482 \tcorrect 146\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "model.train()\n",
    "optimizer = pv.optim.SGD(model.parameters())\n",
    "cceloss = pv.nn.loss.NLL_Loss()\n",
    "\n",
    "for e in range(epoch):\n",
    "    full_loss = 0\n",
    "    n_loss = 0\n",
    "    n_eval = 0\n",
    "    correct = 0\n",
    "    for i, (x, y) in enumerate(dataloader(\"data/cifar-10-batches-py/data_batch_1\")):\n",
    "        print(\"epoch\", e, \"\\tbatch\", i, end = \" \")\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = cceloss(y, output)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer._step()\n",
    "\n",
    "        full_loss += loss.item()\n",
    "        n_loss += batch\n",
    "\n",
    "        np_output = np.array(output.data, copy=False)\n",
    "        mask = np_output.argmax(1) == y\n",
    "        correct += sum(mask)\n",
    "\n",
    "        print(\"\\tloss\", loss, \"\\tcorrect\", correct)\n",
    "    print(f\"Train Accuracy: {correct/n_loss}%\")\n",
    "    print(f\"Epoch: {epoch}, Loss: {full_loss / n_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e14716-b749-4721-ba45-7bcc996a7ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pv.utils.storage.save_parameters(model.state_dict(), \"train2.model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
